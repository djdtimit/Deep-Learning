{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fundamentals_Deep_Learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/djdtimit/Deep-Learning/blob/master/Fundamentals_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bsv4sA4E9CFL",
        "colab_type": "text"
      },
      "source": [
        "# Fundamentals of Deep Learning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6SMeja2AhxQ",
        "colab_type": "code",
        "outputId": "4a0492a8-353d-40a6-f2e0-51500d3b03ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import keras as kf\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "print(kf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n",
            "2.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_caWPrI9bM7",
        "colab_type": "text"
      },
      "source": [
        "## two essential characteristics of how deep learning learns from data (Chollet: Deep Learning with python, p. 18)\n",
        "\n",
        "- incremental, layer-by-layer way in which increasingly complex representations are developed\n",
        "- these intermediate incremental representations are learned jointly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGMyRLIZ9exw",
        "colab_type": "text"
      },
      "source": [
        "## three importand properties of deep learning (Chollet: Deep Learning with python, p. 23)\n",
        "\n",
        "- Simplicity: Deep learning removes the need for feature engineering, replacing\n",
        "complex, brittle, engineering-heavy pipelines with simple, end-to-end trainable\n",
        "models that are typically built using only five or six different tensor operations.\n",
        "\n",
        "- Scalability: Deep learning is highly amenable to parallelization on GPUs or\n",
        "TPUs, so it can take full advantage of Moore’s law. In addition, deep-learning\n",
        "models are trained by iterating over small batches of data, allowing them to be\n",
        "trained on datasets of arbitrary size. \n",
        "\n",
        "- Versatility and reusability: Unlike many prior machine-learning approaches,\n",
        "deep-learning models can be trained on additional data without restarting from\n",
        "scratch, making them viable for continuous online learning—an important\n",
        "property for very large production models. Furthermore, trained deep-learning\n",
        "models are repurposable and thus reusable (transfer learning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZToiZIdu9lF3",
        "colab_type": "text"
      },
      "source": [
        "## What is a tensor?\n",
        "\n",
        "A tensor is a container for data—almost always numerical data. So, it’s a\n",
        "container for numbers. You may be already familiar with matrices, which are 2D tensors: tensors are a generalization of matrices to an arbitrary number of dimensions\n",
        "(note that in the context of tensors, a dimension is often called an axis)\n",
        "\n",
        "A tensor is defined by three key attributes:\n",
        "\n",
        "- Number of axes (rank): For instance, a 3D tensor has three axes, and a matrix has\n",
        "two axes. This is also called the tensor’s ndim in Python libraries such as Numpy.\n",
        "\n",
        "- Shape: This is a tuple of integers that describes how many dimensions the tensor has along each axis. For instance, the previous matrix example has shape\n",
        "(3, 5), and the 3D tensor example has shape (3, 3, 5). A vector has a shape\n",
        "with a single element, such as (5,), whereas a scalar has an empty shape, ().\n",
        "\n",
        "- Data type (usually called dtype in Python libraries): This is the type of the data\n",
        "contained in the tensor; for instance, a tensor’s type could be float32, uint8,\n",
        "float64, and so on. On rare occasions, you may see a char tensor. Note that\n",
        "string tensors don’t exist in Numpy (or in most other libraries), because tensors\n",
        "live in preallocated, contiguous memory segments: and strings, being variable\n",
        "length, would preclude the use of this implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EZN9y1DArW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6lvNuPKA4Vr",
        "colab_type": "code",
        "outputId": "4580601e-a7de-4834-c7f2-fac8a2c4ae66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 9s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CZexpeLBmud",
        "colab_type": "code",
        "outputId": "3a47f7fc-80ea-4802-9332-d6e5267b4380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print('axes: ', train_images.ndim)\n",
        "# 60000 images\n",
        "print('shape: ', train_images.shape)\n",
        "print('dtype: ', train_images.dtype)\n",
        "print('type: ', type(train_images))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "axes:  3\n",
            "shape:  (60000, 28, 28)\n",
            "dtype:  uint8\n",
            "type:  <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwCap9FJHPbg",
        "colab_type": "text"
      },
      "source": [
        "axis 0 = samples axes or batch axes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u71hTLRb9uX_",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "- scaling of input data into the [0, 1] interval\n",
        "- reshaping of data\n",
        "- categorically encoding of the labels\n",
        "- one-hot encoding\n",
        "- vectorizing of data since only tensors are allowed as input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoVKxop-e0tZ",
        "colab_type": "text"
      },
      "source": [
        "## Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3NKiClTe4fX",
        "colab_type": "text"
      },
      "source": [
        "- densely connected or fully connected layers: simple vector data, stored in 2D tensors of shape (samples,features) -> sentiment analysis\n",
        "\n",
        "- recurrent layers: Sequence data, stored in 3D tensors of shape (samples,timesteps, features)\n",
        "\n",
        "- 2D convolution layers (Conv2D): Image data, stored in 4D tensors\n",
        "\n",
        "- information bottleneck: layer with small number of neurons dropping relevant information -> increase number of neurons for example in a multiclass classification problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luL_RguNhF4w",
        "colab_type": "text"
      },
      "source": [
        "## Loss functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjj9C0j1htVq",
        "colab_type": "text"
      },
      "source": [
        "- binary crossentropy: two-class classification\n",
        "  \n",
        "- categorical crossentropy: many-class classification problem\n",
        "  \n",
        "- meansquared error: regression problem\n",
        "  \n",
        "- connectionist temporal classification (CTC): sequence-learning problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nu22nZETeMA_",
        "colab_type": "text"
      },
      "source": [
        "## Activation functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfx9RSqAeMFO",
        "colab_type": "text"
      },
      "source": [
        "- activation functions are necessary to introduce non-linearity in order to get access to a much richer hypthesis space that would benefit from deep representations\n",
        "\n",
        "- relu is a good choice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l26VEr14irdW",
        "colab_type": "text"
      },
      "source": [
        "## Optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bM_P7IxSirjE",
        "colab_type": "text"
      },
      "source": [
        "- rmsprop is a good choice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Czqvy0h6jGAz",
        "colab_type": "text"
      },
      "source": [
        "## binary classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKbfg-xxjGHf",
        "colab_type": "text"
      },
      "source": [
        "- network should end with a Dense layer with one unit and sigmoid activation function\n",
        "\n",
        "- loss_function: binary_crossentropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqIYNZdrPJOI",
        "colab_type": "text"
      },
      "source": [
        "## classification problems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbTuU49oPOBO",
        "colab_type": "text"
      },
      "source": [
        "- single label, multiclass classification: many classes but a classification into one catgory\n",
        "\n",
        "- multi label, multiclass classification: each data point could belong to multiple classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thyA4lPzaWar",
        "colab_type": "text"
      },
      "source": [
        "## multiclass classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4CvakSFafWZ",
        "colab_type": "text"
      },
      "source": [
        "- network should end with a softmax activation function\n",
        "\n",
        "- not too few neurons per layer (see information bottleneck)\n",
        "\n",
        "- loss function: categorical_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCxixc5iYJrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}